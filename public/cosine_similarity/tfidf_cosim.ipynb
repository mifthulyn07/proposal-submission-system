{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d1370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!C:/Users/Administrator/anaconda3/python.exe\n",
    "import sys\n",
    "import json\n",
    "\n",
    "#import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#dibaca oleh laravel \n",
    "import sys\n",
    "import json\n",
    "\n",
    "#untuk preprocessing\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize #tokenezing\n",
    "from nltk.corpus import stopwords #stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory #stemming\n",
    "import re #cleaning\n",
    "\n",
    "#Untuk Tf-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#untuk cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "#=================================================\n",
    "\n",
    "similarity = sys.argv[1]\n",
    "\n",
    "# corpus = '{\"name\":[\"data uji\",\"Miftahul Ulyana Hutabarat\",\"Developer\",\"Developer\",\"Developerr\",\"Developer\",\"Miftahul Ulyana Hutabarat\",\"Miftahul Ulyana Hutabarat\",\"Miftahul Ulyana Hutabarat\",\"Developer\",\"vdfvd\",\"Miftahul Ulyana Hutabarat\",\"Developer\",\"Developer\",\"Miftahul Ulyana Hutabarat\",\"Miftahul Ulyana Hutabarat\",\"Miftahul Ulyana Hutabarat\",\"Developer\",\"Developer\",\"Developer\",\"Miftahul Ulyana Hutabarat\",\"cindai\",\"Developer\",\"Miftahul Ulyana Hutabarat\",\"Developer\",\"Developer\",\"Miftahul Ulyana Hutabarat\",\"Developer\",\"Miftahul Ulyana Hutabarat\",\"Developer\",\"Miftahul Ulyana Hutabarat\",\"Developer\",\"Miftahul Ulyana Hutabarat\",\"Miftahul Ulyana Hutabarat\",\"Miftahul Ulyana Hutabarat\",\"Miftahul Ulyana Hutabarat\"],\"nim\":[\"data uji\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192032\",\"0702192033\",\"333313\",\"0702192031\",\"0702192031\",\"53252\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"0702192031\",\"07021920390\",\"0702192032\",\"0702192031\",\"07021920309\",\"0702192039\"],\"year\":[\"data uji\",\"2023\",\"2023\",\"2021\",\"2021\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"2023\",\"4323\",\"3454\",\"4322\",\"2023\",\"2021\",\"1234\",\"4323\",\"3454\",\"3454\",\"4322\",\"2021\",\"4323\",\"4322\",\"4322\",\"3454\",\"7586\",\"2021\"],\"title\":[\"cindai\",\"nkjiuhilj\",\"fvfdv\",\"apalahkauni\",\"apalahauni\",\"fsfes\",\"vbdvs\",\"dfvsdfv\",\"dcdscs\",\"vvwc\",\"vefvv\",\"cdcdc\",\"bhgth\",\"jbjh\",\"cfdsd\",\"dscs\",\"cdscds\",\"cdca\",\"edad\",\"vva\",\"dvvsdf\",\"fafds\",\"sgverv\",\"xbzsb\",\"dbvsb\",\"jkbkb\",\"hbjh\",\" hjmbmn\",\"hjhg\",\"bjhkj\",\"etheh\",\"jvmhsvvs\",\"gvmjh\",\"hghg\",\"csCSdvdsv\",\"fsvdfvdfv\"]}'\n",
    "# corpus = json.loads(corpus)\n",
    "\n",
    "# name    = corpus['name']\n",
    "# nim     = corpus['nim']\n",
    "# year    = corpus['year']\n",
    "# title   = corpus['title']\n",
    "\n",
    "# corpus_combined = list(zip(name, nim, year, title))\n",
    "\n",
    "# cosim = preprocess_tfidf_cosim(corpus_combined)\n",
    "\n",
    "# data_dict = cosim.to_dict(orient='records')\n",
    "# cosim = json.dumps(data_dict)\n",
    "\n",
    "print(similarity)\n",
    "\n",
    "#==================================================\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    lowercased_text = text.lower()\n",
    "\n",
    "    # Cleaning\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', lowercased_text)\n",
    "\n",
    "    # Tokenization\n",
    "    tokenized_text = word_tokenize(cleaned_text)\n",
    "\n",
    "    # Stemming\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    stemmed_text = [stemmer.stem(word) for word in tokenized_text]\n",
    "\n",
    "    # Unique Words\n",
    "    unique_words = list(set(stemmed_text))\n",
    "\n",
    "    # Stop Words\n",
    "    stopwords_indonesia = set(stopwords.words('indonesian'))\n",
    "    stopwords_removed = [word for word in unique_words if word not in stopwords_indonesia]\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Original Text': [text],\n",
    "        'Lowercasing' : [lowercased_text],\n",
    "        'Cleaning': [cleaned_text],\n",
    "        'Tokenization': [tokenized_text],\n",
    "        'Stemming': [stemmed_text],\n",
    "        'Unique Words': [unique_words],\n",
    "        'Stop Words': [stopwords_removed]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "    \n",
    "#==================================================\n",
    "\n",
    "def preprocess_tfidf_cosim(corpus):  \n",
    "        \n",
    "    def preprocessing(corpus):\n",
    "        # Create DataFrames kosong\n",
    "        df = pd.DataFrame(columns=['Name', 'Nim', 'Year', 'Original Text'])\n",
    "\n",
    "        #preprocessing dan memasukkan kedalam df\n",
    "        for item in corpus:\n",
    "            # Extract informasi dari corpus\n",
    "            name = item[0]\n",
    "            nim  = item[1]\n",
    "            year = item[2]\n",
    "            text = item[3]\n",
    "\n",
    "            # print(len(text))\n",
    "            # Preprocessing\n",
    "            result_df = preprocess_text(text)\n",
    "\n",
    "            # masukkan value item ke dalam kolom\n",
    "            result_df['Name'] = name\n",
    "            result_df['Nim']  = nim\n",
    "            result_df['Year'] = year\n",
    "            \n",
    "            # satukan hasil preprocessing ke DataFrame utama sesuai dengan nama\n",
    "            df = pd.concat([df, result_df], ignore_index=True)\n",
    "        return df\n",
    "    \n",
    "    def tfidf(corpus):\n",
    "        #paggil hasil preprocessing\n",
    "        df = preprocessing(corpus)\n",
    "        \n",
    "        #membuat kolom baru dengan header kosong dan join setelah stopwords, memasukkan nilai bobot disetiap header yg kosong\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(df['Stop Words'].apply(' '.join))\n",
    "        \n",
    "        #ambil kata dari array stopwords untuk di jadikan header\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        #satukan judul header dan bobotnya\n",
    "        df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "        df_tfidf = pd.concat([df, df_tfidf], axis=1)\n",
    "        \n",
    "        return df_tfidf\n",
    "    \n",
    "    def cosineSimilarity(corpus):\n",
    "        df_tfidf = tfidf(corpus)\n",
    "        \n",
    "        # Mengambil vektor TF-IDF untuk item pertama (index 0)\n",
    "        vector1 = df_tfidf.iloc[0, 10:].values.reshape(1, -1)\n",
    "\n",
    "        # Mengambil vektor TF-IDF untuk semua item kecuali item pertama\n",
    "        #vectors = tfidf_df.iloc[1:, 10:].values\n",
    "        vectors = df_tfidf.iloc[:, 10:].values\n",
    "\n",
    "        # Menghitung cosine similarity antara item pertama dan semua item lainnya\n",
    "        cosim = cosine_similarity(vector1, vectors)\n",
    "        \n",
    "        cosim = pd.DataFrame(cosim)\n",
    "        # Mengubah DataFrame menjadi array satu dimensi\n",
    "        cosim = cosim.values.flatten()\n",
    "\n",
    "        # Mengubah hasil cosine similarity menjadi DataFrame\n",
    "        df_cosim = pd.DataFrame(cosim, columns=['cosim'])\n",
    "\n",
    "        #menghitung persenan\n",
    "        df_cosim['percent'] = df_cosim['cosim'] * 100\n",
    "        \n",
    "        # Menggabungkan array TF-IDF dengan hasil cosine similarity\n",
    "        df_cosim = pd.concat([df_tfidf, df_cosim], axis=1)\n",
    "\n",
    "        return df_cosim\n",
    "    \n",
    "    return cosineSimilarity(corpus)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
